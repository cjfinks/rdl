""" Test's Darren's vision that we should find a high density of samples around a k-dimensional subspace, which would be a very suspicious coincidence in a high-dimenal ambient space unless they were all
generated by the same k dictionary elements."""

import numpy as np

m = 10 # dimension of underlying sparse codes, i.e. number of dictionary elements
k = 3 # sparsity
n = 3 # dimension of compressed vectors

""" Initialize a dictionary of norm 1 vectors that satisfies RIP """
# Does this satisfy the RIP? Probably..?
A = 2*np.random.rand( n, m ) - 1
A /= np.sqrt(np.sum( A**2, axis = 0 ))[None, :] # scale columns to have norm 1
#A *= np.sign( np.sum( A, axis=0 ) )
A *= np.sign( A[2] )

""" Generate dataset of k-sparse m-dimensional vectors """
N = 1000
a = np.zeros( (N, m) )
for a_ in a:
	supp = np.random.random_integers(0, m-1, k)
	coef = np.random.rand(k)
	a_[supp] = coef

""" Make compressed noisy measurements """
#y = np.dot( a, A.T )
t = np.arange(1000) # draw a spiral
y = np.array( [t * np.cos(t), t * np.sin(t), t ]).T / 1000
noise = np.random.rand(N, n)
noise /= np.sqrt(np.sum( noise**2, axis = 1 ))[:, None] # scale columns to have norm 1
#y += 0.01 * noise

""" Plot measurements in 3-space """
import matplotlib.pyplot as pp
from mpl_toolkits.mplot3d import Axes3D
pp.ion()
fig = pp.figure()
ax = fig.add_subplot(111, projection='3d') # requires Axes3D
ax.scatter( y.T[0], y.T[1], y.T[2], s = 2 )
pp.show()

""" Draw dictionary elements """
"""
from utils import Arrow3D
for vec in A.T:
	arrow = Arrow3D([0,vec[0]],[0,vec[1]],[0,vec[2]], mutation_scale=20, lw=1, arrowstyle="-|>", color="k")
	ax.add_artist(arrow)
pp.draw()
"""

""" Do dictionary learning """
from sparse_model import SparseModel
import theano
import theano.tensor as T
lrate = 3e-2
nb = 16
data = theano.shared(y.astype(np.float32))
model = SparseModel(nx = n, ns = m, nb = nb, xvar = 0.001, sparsity = 100.0)
x = T.fmatrix()
lr = T.fscalar()
idxs = T.lscalar()
objs, ss, learn_updates = model.update_params(x, lr)
train_model = theano.function([idxs, lr],
		                      [objs, ss],
		                      updates = learn_updates,
							  givens = {x: data[ idxs:idxs + nb, : ]},
							  allow_input_downcast = True )
for i in range(1000):
	idx = np.random.randint( N - nb ) # starting index of batch (batch is idx:idx+nb)
	var_exp, ssh = train_model( idx, lrate ) # train over one batch
	print var_exp #pp.plot(var_exp); pp.show() # print progress
Ahat = model.W.get_value() # cols are dict elements
#Ahat *= np.sign( np.sum( Ahat, axis=0 ) )
Ahat *= np.sign( Ahat[2] )

""" Draw estimated dictionary elements """
from utils import Arrow3D
for vec in Ahat.T:
	arrow = Arrow3D([0,vec[0]],[0,vec[1]],[0,vec[2]], mutation_scale=20, lw=1, arrowstyle="-|>", color="r")
	ax.add_artist(arrow)
pp.draw()
