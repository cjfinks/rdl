
Cover Letter


We submit the original work "When is sparse dictionary learning well-posed?" to IEEE Signal Processing Letters.

A basic question that has been hovering over the field of sparse dictionary learning (also called sparse coding) is how to interpret learned "basis functions" trained over a dataset such as natural images or MRI recordings.  Here, we give one powerful and satisfactory answer:  Given a sufficiently diverse noisy dataset generated by a matrix satisfying the spark condition, any other dictionary sparsely coding it accurately is the same as the original up to the natural symmetries in the problem and the measurement error (and this holds for the codes as well).  

This finding was previously only proved in the exact case (no measurement noise), and so our contribution is a generalization of this uniqueness statement to the case of measurement error, which is the only important case for applications.

One remark: *both authors* are to be designated as *corresponding authors*:

Charles J. Garfinkle
Christopher J. Hillar

(the online web submission does not allow for this option, but we would like to invoke it)

Redwood Center for Theoretical Neuroscience
University of California, Berkeley
